{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgNZTjrhcHa0"
   },
   "source": [
    "<center><h1>CSCI 4140: Natural Language Processing</h1></center>\n",
    "<center><h1>CSCI/DASC 6040: Computational Analysis of Natural Languages</h1></center>\n",
    "\n",
    "<center><h6>Spring 2023</h6></center>\n",
    "<center><h6>Homework 2 - Types, tokens and Zipf's law; sentiment analysis with naive Bayes</h6></center>\n",
    "<center><h6>Due Sunday, February 12, at 11:59 PM</h6></center>\n",
    "\n",
    "<font color='red'>Do not redistribute without the instructor’s written permission.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "prxVeM9KHSS6",
    "outputId": "70efa692-9772-44f4-e470-2652c4f52943"
   },
   "outputs": [],
   "source": [
    "# Run this cell! It sets some things up for you.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division  # this line is important to avoid unexpected behavior from division\n",
    "import os\n",
    "import zipfile\n",
    "import math\n",
    "import time\n",
    "import operator\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 4) # set default size of plots\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')  # make the data directory\n",
    "\n",
    "# Extract the data from the zipfile and put it into the data directory\n",
    "with zipfile.ZipFile('large_movie_review_dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "print(\"IMDb data extracted!\")\n",
    "\n",
    "PATH_TO_DATA = 'data/large_movie_review_dataset'  # path to the data directory\n",
    "POS_LABEL = 'pos'\n",
    "NEG_LABEL = 'neg'\n",
    "TRAIN_DIR = os.path.join(PATH_TO_DATA, \"train\")\n",
    "TEST_DIR = os.path.join(PATH_TO_DATA, \"test\")\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    if len(os.listdir(TRAIN_DIR + \"/\" + label)) == 12500:\n",
    "        print (\"Great! You have 12500 {} reviews in {}\".format(label, TRAIN_DIR + \"/\" + label))\n",
    "    else:\n",
    "        print (\"Oh no! Something is wrong. Check your code which loads the reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qGJaL6n4O-d7",
    "outputId": "63347000-7c20-4f4a-c7f9-58c8c0a3b616"
   },
   "outputs": [],
   "source": [
    "# Actually reading the data you are working with is an important part of NLP! Let's look at one of these reviews\n",
    "\n",
    "print (open(TRAIN_DIR + \"/neg/98_1.txt\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvX4ydsdmnfd"
   },
   "source": [
    "# Preprocessing Block\n",
    "<a id='Preprocessing-Block'></a>\n",
    "The following cell contains code that will be referred to as the `Preprocessing Block` from now on. It contains a function that tokenizes the document passed to it, and functions that return counts of word types and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKSU5Y3Cmoo_"
   },
   "outputs": [],
   "source": [
    "###### PREPROCESSING BLOCK ######\n",
    "\n",
    "###### DO NOT MODIFY THIS FUNCTION #####\n",
    "def tokenize_doc(doc):\n",
    "    \"\"\"\n",
    "    Tokenize a document and return its bag-of-words representation.\n",
    "    doc - a string representing a document.\n",
    "    returns a dictionary mapping each word to the number of times it appears in doc.\n",
    "    \"\"\"\n",
    "    bow = defaultdict(float)\n",
    "    tokens = doc.split()\n",
    "    lowered_tokens = map(lambda t: t.lower(), tokens)\n",
    "    for token in lowered_tokens:\n",
    "        bow[token] += 1.0\n",
    "    return dict(bow)\n",
    "###### END FUNCTION #####\n",
    "\n",
    "def n_word_types(word_counts):\n",
    "    '''\n",
    "    Implement Me!\n",
    "    return a count of all word types in the corpus\n",
    "    using information from word_counts\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def n_word_tokens(word_counts):\n",
    "    '''\n",
    "    Implement Me!\n",
    "    return a count of all word tokens in the corpus\n",
    "    using information from word_counts\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOqZ7aacWewe"
   },
   "source": [
    "# Naive Bayes Block\n",
    "<a id='Naive-Bayes-Block'></a>\n",
    "This next block of code (referred to as `Naive Bayes Block` from now on) is something you will keep coming back to throughout the course of the assignment. There are several functions you need to implement here, that will be called in later parts of the assignment. Familiarize yourself with what each function does, as well as how everything comes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4ZzCKADPDCP"
   },
   "outputs": [],
   "source": [
    "###### NAIVE BAYES BLOCK ######\n",
    "\n",
    "class NaiveBayes:\n",
    "    \"\"\"A Naive Bayes model for text classification.\"\"\"\n",
    "\n",
    "    def __init__(self, path_to_data, tokenizer):\n",
    "        # Vocabulary is a set that stores every word seen in the training data\n",
    "        self.vocab = set()\n",
    "        self.path_to_data = path_to_data\n",
    "        self.tokenize_doc = tokenizer\n",
    "        self.train_dir = os.path.join(path_to_data, \"train\")\n",
    "        self.test_dir = os.path.join(path_to_data, \"test\")\n",
    "        # class_total_doc_counts is a dictionary that maps a class (i.e., pos/neg) to\n",
    "        # the number of documents in the trainning set of that class\n",
    "        self.class_total_doc_counts = { POS_LABEL: 0.0,\n",
    "                                        NEG_LABEL: 0.0 }\n",
    "\n",
    "        # class_total_word_counts is a dictionary that maps a class (i.e., pos/neg) to\n",
    "        # the number of words in the training set in documents of that class\n",
    "        self.class_total_word_counts = { POS_LABEL: 0.0,\n",
    "                                         NEG_LABEL: 0.0 }\n",
    "\n",
    "        # class_word_counts is a dictionary of dictionaries. It maps a class (i.e.,\n",
    "        # pos/neg) to a dictionary of word counts. For example:\n",
    "        #    self.class_word_counts[POS_LABEL]['awesome']\n",
    "        # stores the number of times the word 'awesome' appears in documents\n",
    "        # of the positive class in the training documents.\n",
    "        self.class_word_counts = { POS_LABEL: defaultdict(float),\n",
    "                                   NEG_LABEL: defaultdict(float) }\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        This function processes the entire training set using the global PATH\n",
    "        variable above.  It makes use of the tokenize_doc and update_model\n",
    "        functions you will implement.\n",
    "        \"\"\"\n",
    "\n",
    "        pos_path = os.path.join(self.train_dir, POS_LABEL)\n",
    "        neg_path = os.path.join(self.train_dir, NEG_LABEL)\n",
    "        for (p, label) in [ (pos_path, POS_LABEL), (neg_path, NEG_LABEL) ]:\n",
    "            for f in os.listdir(p):\n",
    "                with open(os.path.join(p,f),'r') as doc:\n",
    "                    content = doc.read()\n",
    "                    self.tokenize_and_update_model(content, label)\n",
    "        self.report_statistics_after_training()\n",
    "\n",
    "    def report_statistics_after_training(self):\n",
    "        \"\"\"\n",
    "        Report a number of statistics after training.\n",
    "        \"\"\"\n",
    "\n",
    "        print (\"REPORTING CORPUS STATISTICS\")\n",
    "        print (\"NUMBER OF DOCUMENTS IN POSITIVE CLASS:\", self.class_total_doc_counts[POS_LABEL])\n",
    "        print (\"NUMBER OF DOCUMENTS IN NEGATIVE CLASS:\", self.class_total_doc_counts[NEG_LABEL])\n",
    "        print (\"NUMBER OF TOKENS IN POSITIVE CLASS:\", self.class_total_word_counts[POS_LABEL])\n",
    "        print (\"NUMBER OF TOKENS IN NEGATIVE CLASS:\", self.class_total_word_counts[NEG_LABEL])\n",
    "        print (\"VOCABULARY SIZE: NUMBER OF UNIQUE WORDTYPES IN TRAINING CORPUS:\", len(self.vocab))\n",
    "\n",
    "    def update_model(self, bow, label):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Update internal statistics given a document represented as a bag-of-words\n",
    "        bow - a map from words to their counts\n",
    "        label - the class of the document whose bag-of-words representation was input\n",
    "        This function doesn't return anything but should update a number of internal\n",
    "        statistics. Specifically, it updates:\n",
    "          - the internal map the counts, per class, how many times each word was\n",
    "            seen (self.class_word_counts)\n",
    "          - the number of words seen for each label (self.class_total_word_counts)\n",
    "          - the vocabulary seen so far (self.vocab)\n",
    "          - the number of documents seen of each label (self.class_total_doc_counts)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def tokenize_and_update_model(self, doc, label):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Tokenizes a document doc and updates internal count statistics.\n",
    "        doc - a string representing a document.\n",
    "        label - the sentiment of the document (either postive or negative)\n",
    "        stop_word - a boolean flag indicating whether to stop word or not\n",
    "\n",
    "        Make sure when tokenizing to lower case all of the tokens!\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def top_n(self, label, n):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "        \n",
    "        Returns the most frequent n tokens for documents with class 'label'.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def p_word_given_label(self, word, label):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Returns the probability of word given label\n",
    "        according to this NB model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def p_word_given_label_and_alpha(self, word, label, alpha):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Returns the probability of word given label wrt psuedo counts.\n",
    "        alpha - pseudocount parameter\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def log_likelihood(self, bow, label, alpha):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Computes the log likelihood of a set of words given a label and pseudocount.\n",
    "        bow - a bag of words (i.e., a tokenized document)\n",
    "        label - either the positive or negative label\n",
    "        alpha - float; pseudocount parameter\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def log_prior(self, label):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Returns the log prior of a document having the class 'label'.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def unnormalized_log_posterior(self, bow, label, alpha):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Computes the unnormalized log posterior (of doc being of class 'label').\n",
    "        bow - a bag of words (i.e., a tokenized document)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def classify(self, bow, alpha):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Compares the unnormalized log posterior for doc for both the positive\n",
    "        and negative classes and returns the either POS_LABEL or NEG_LABEL\n",
    "        (depending on which resulted in the higher unnormalized log posterior)\n",
    "        bow - a bag of words (i.e., a tokenized document)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def likelihood_ratio(self, word, alpha):\n",
    "        \"\"\"\n",
    "        Implement me!\n",
    "\n",
    "        Returns the ratio of P(word|pos) to P(word|neg).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def evaluate_classifier_accuracy(self, alpha):\n",
    "        \"\"\"\n",
    "        DO NOT MODIFY THIS FUNCTION\n",
    "\n",
    "        alpha - pseudocount parameter.\n",
    "        This function should go through the test data, classify each instance and\n",
    "        compute the accuracy of the classifier (the fraction of classifications\n",
    "        the classifier gets right.\n",
    "        \"\"\"\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        pos_path = os.path.join(self.test_dir, POS_LABEL)\n",
    "        neg_path = os.path.join(self.test_dir, NEG_LABEL)\n",
    "        for (p, label) in [ (pos_path, POS_LABEL), (neg_path, NEG_LABEL) ]:\n",
    "            for f in os.listdir(p):\n",
    "                with open(os.path.join(p,f),'r') as doc:\n",
    "                    content = doc.read()\n",
    "                    bow = self.tokenize_doc(content)\n",
    "                    if self.classify(bow, alpha) == label:\n",
    "                        correct += 1.0\n",
    "                    total += 1.0\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vWoaBpQYKzq"
   },
   "source": [
    "# Part One: Intro to NLP in Python: types, tokens and Zipf's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EM2aVbUcYPXv"
   },
   "source": [
    "## Types and tokens\n",
    "\n",
    "One major part of any NLP project is word tokenization. Word tokenization is the task of segmenting text into individual words, called tokens. In this assignment, we will use simple whitespace tokenization. Take a look at the `tokenize_doc` function in the [Preprocessing Block](#Preprocessing-Block) above. **You should not modify tokenize_doc** but make sure you understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "W9Fm6AQJQDFa",
    "outputId": "7e53bdbd-aa60-4c70-9858-bb17df427e40"
   },
   "outputs": [],
   "source": [
    "d1 = \"This SAMPLE doc has   words tHat  repeat repeat\"\n",
    "bow = tokenize_doc(d1)\n",
    "\n",
    "assert bow['this'] == 1\n",
    "assert bow['sample'] == 1\n",
    "assert bow['doc'] == 1\n",
    "assert bow['has'] == 1\n",
    "assert bow['words'] == 1\n",
    "assert bow['that'] == 1\n",
    "assert bow['repeat'] == 2\n",
    "\n",
    "bow2 = tokenize_doc(\"NLP is my favorite class this semester!\")\n",
    "for b in bow2:\n",
    "    print (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5f5YpclYjbh"
   },
   "source": [
    "Now we are going to look at the word types and word tokens in the corpus.\n",
    "Use the `word_counts` dictionary variable to store the count of each word in the corpus.\n",
    "Use the `tokenize_doc` function to break documents into tokens. **You should not modify tokenize_doc** but make sure you understand what it is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9OxWy-CYlp4"
   },
   "source": [
    "### Question 1.1 (5 points)\n",
    "\n",
    "Complete the cell below to fill out the `word_counts` dictionary variable. `word_counts` keeps track of how many times a word type appears across the corpus. For instance, `word_counts[\"movie\"]` should store the number 61492, the count of how many times the word `movie` appears in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su_j1JY1QG5f"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import codecs\n",
    "word_counts = Counter() # Counters are often useful for NLP in python\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    for directory in [TRAIN_DIR, TEST_DIR]:\n",
    "        for fn in glob.glob(directory + \"/\" + label + \"/*txt\"):\n",
    "            doc = codecs.open(fn, 'r', 'utf8') # Open the file with UTF-8 encoding\n",
    "            # IMPLEMENT ME\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3q-GnAwERM1C",
    "outputId": "df7d6964-fb29-410d-a4ad-bd5824c0b768"
   },
   "outputs": [],
   "source": [
    "if word_counts[\"movie\"] == 61492:\n",
    "    print (\"yay! there are {} total instances of the word type movie in the corpus\".format(word_counts[\"movie\"]))\n",
    "else:\n",
    "    print (\"hmm. Something seems off. Double check your code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F41LYDeoZPYI"
   },
   "source": [
    "### Question 1.2 (5 points)\n",
    "\n",
    "Fill out the functions `n_word_types`, `n_word_tokens` in the [Preprocessing Block](#Preprocessing-Block).\n",
    "\n",
    "***Note: you will have to rerun the `Preprocessing Block` cell every time you change its code for it to have any effect!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AElitE39SHJ9",
    "outputId": "55c4782a-5d82-4d73-bfac-e5bb3f96b910"
   },
   "outputs": [],
   "source": [
    "print (\"there are {} word types in the corpus\".format(n_word_types(word_counts)))\n",
    "print (\"there are {} word tokens in the corpus\".format(n_word_tokens(word_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-xGz2_cZVs7"
   },
   "source": [
    "<font color='red'>What is the difference between word types and tokens? Why are the number of tokens much higher than the number of types?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mm3KgZwuL23k"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOlrqnSqZ3H8"
   },
   "source": [
    "### Question 1.3 (5 points)\n",
    "\n",
    "Using the `word_counts` dictionary you just created, make a new dictionary called `sorted_dict` where the words are sorted according to their counts, in decending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZarWwkESM7-"
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UfCttSMGaLxD"
   },
   "source": [
    "Now print the first 30 values from sorted_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "4y3-haXESUhs",
    "outputId": "b4d765ca-ce37-4d73-864f-9d5de43f3ef4"
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKItixbCaYCx"
   },
   "source": [
    "## Zipf's Law\n",
    "\n",
    "### Question 1.4 (10 points)\n",
    "\n",
    "In this section, you will verify a key statistical property of text: [Zipf's Law](https://en.wikipedia.org/wiki/Zipf%27s_law).\n",
    "\n",
    "Zipf's Law describes the relations between the frequency rank of words and frequency value of words.  For a word $w$, its frequency is inversely proportional to its rank:\n",
    "\n",
    "$$count_w = K \\frac{1}{rank_w}$$\n",
    "\n",
    "$K$ is a constant, specific to the corpus and how words are being defined.\n",
    "\n",
    "<font color='red'>What would this look like if you took the log of both sides of the equation?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKItixbCaYCx"
   },
   "source": [
    "Therefore, if Zipf's Law holds, after sorting the words descending on frequency, word frequency decreases in an approximately linear fashion under a log-log scale.\n",
    "\n",
    "<font color='red'>Now, please make such a log-log plot by plotting the rank versus frequency</font>\n",
    "\n",
    "*Hint: Make use of the sorted dictionary you just created.*\n",
    "Use a scatter plot where the x-axis is the *log(rank)*, and y-axis is *log(frequency)*.  You should get this information from `word_counts`; for example, you can take the individual word counts and sort them.  dict methods `.items()` and/or `values()` may be useful.  (Note that it doesn't really matter whether ranks start at 1 or 0 in terms of how the plot comes out.) You can check your results by comparing your plots to ones on Wikipedia; they should look qualitatively similar.\n",
    "\n",
    "*Please remember to label the meaning of the x-axis and y-axis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "b76z9aMUSbHB",
    "outputId": "4e24ba7d-2bac-45f0-ca2a-fde8522e43e8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "x = []\n",
    "y = []\n",
    "X_LABEL = \"log(rank)\"\n",
    "Y_LABEL = \"log(frequency)\"\n",
    "\n",
    "# Add your code here\n",
    "# You should fill the x and y arrays.\n",
    "# Running this cell should produce your plot below.\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(X_LABEL)\n",
    "plt.ylabel(Y_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eFFC81OaT8KD"
   },
   "source": [
    "# Part Two: Naive Bayes\n",
    "\n",
    "This section of the homework will walk you through coding a Naive Bayes classifier that can distinguish between positive and negative reviews (with some level of accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgfvzKO5UFzz"
   },
   "source": [
    "## Question 2.1 (10 pts)\n",
    "\n",
    "To start, implement the `update_model` and `tokenize_and_update_model` functions in the [Naive Bayes Block](#Naive-Bayes-Block). Make sure to read the functions' comments so you know what to update. Also review the `NaiveBayes` class variables in the `def __init__` method of the `NaiveBayes class` to get a sense of which statistics are important to keep track of. Once you have implemented `update_model`, run the train model function using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "EE88tvjbSfCb",
    "outputId": "2f3e7f3a-4b9d-4a40-f612-1df379d6dbd6"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc)\n",
    "nb.train_model()\n",
    "\n",
    "if len(nb.vocab) == 251637:\n",
    "    print (\"Great! The vocabulary size is {}\".format(251637))\n",
    "else:\n",
    "    print (\"Oh no! Something seems off. Double check your code before continuing. Maybe a mistake in update_model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmhU3HGcUdcV"
   },
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Let’s begin to explore the count statistics stored by the update model function. Implement the provided `top_n` function in the [Naive Bayes Block](#Naive-Bayes-Block) to find the top 10 most common words in the positive class and top 10 most common words in the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "javpxv_NSmIn",
    "outputId": "cf53e389-c699-4c36-eb13-1eb92ed710ff"
   },
   "outputs": [],
   "source": [
    "print (\"TOP 10 WORDS FOR CLASS \" + POS_LABEL + \":\")\n",
    "for tok, count in nb.top_n(POS_LABEL, 10):\n",
    "    print ('', tok, count)\n",
    "print ()\n",
    "\n",
    "print (\"TOP 10 WORDS FOR CLASS \" + NEG_LABEL + \":\")\n",
    "for tok, count in nb.top_n(NEG_LABEL, 10):\n",
    "    print ('', tok, count)\n",
    "print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1H_bbI2nVCaj"
   },
   "source": [
    "### Question 2.2 (5 points)\n",
    "\n",
    "<font color='red'>What is the first thing that you notice when you look at the top 10 words for the 2 classes? Are these words helpful for discriminating between the two classes? Do you imagine that processing other English text will result in a similar phenomenon? What about other languages?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UyodDYmWVF-A"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDzkThMsVMnP"
   },
   "source": [
    "### Question 2.3 (5 points)\n",
    "\n",
    "The Naive Bayes model assumes that all features are conditionally independent given the class label. For our purposes, this means that the probability of seeing a particular word in a document with class label $y$ is independent of the rest of the words in that document. Implement the `p_word_given_label` function in the [Naive Bayes Block](#Naive-Bayes-Block). This function calculates P (w|y) (i.e., the probability of seeing word w in a document given the label of that document is y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FV4qh0XGVb1L"
   },
   "source": [
    "Use your `p_word_given_label` function to compute the probability of seeing the word “amazing” given each sentiment label. Repeat the computation for the word “dull.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8YNbu1MTTaHR",
    "outputId": "44b3fc7b-e994-4e7d-c83d-a5686f1def57"
   },
   "outputs": [],
   "source": [
    "print (\"P('amazing'|pos):\",  nb.p_word_given_label(\"amazing\", POS_LABEL))\n",
    "print (\"P('amazing'|neg):\",  nb.p_word_given_label(\"amazing\", NEG_LABEL))\n",
    "print (\"P('dull'|pos):\",  nb.p_word_given_label(\"dull\", POS_LABEL))\n",
    "print (\"P('dull'|neg):\",  nb.p_word_given_label(\"dull\", NEG_LABEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xG8nZvPXVtXb"
   },
   "source": [
    "<font color='red'>Which word has a higher probability, given the positive class? Which word has a higher probability, given the negative class? Is this behavior expected?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nKh8PEiV4Xt"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcGkRMsuwyro"
   },
   "source": [
    "### Question 2.4 (5 points)\n",
    "\n",
    "In the next cell, compute the probability of the word \"car-thievery\" in the positive training data and negative training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lV6mV3nFTdIj",
    "outputId": "960f5b9e-6299-4bfe-f196-d090ed0352ec"
   },
   "outputs": [],
   "source": [
    "print (\"P('car-thievery'|pos):\",  nb.p_word_given_label(\"car-thievery\", POS_LABEL))\n",
    "print (\"P('car-thievery'|neg):\",  nb.p_word_given_label(\"car-thievery\", NEG_LABEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fFZJVaVw-be"
   },
   "source": [
    "<font color='red'>What is unusual about P('car-thievery'|neg)? What would happen if we took the log of \"P('car-thievery'|neg)\"? What would happen if we multiplied \"P('car-thievery'|neg)\" by \"P('dull'|neg)\"? Why might these operations cause problems for a Naive Bayes classifier?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oap_M5VMbfe"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2vQaoMRxJG4"
   },
   "source": [
    "### Question 2.5 (5 points)\n",
    "\n",
    "We can address the issues from question 2.4 with add-$\\alpha$ smoothing (like add-1 smoothing except instead of adding 1 we add $\\alpha$). Implement\n",
    "`p_word_given_label_and_alpha` in the [Naive Bayes Block](#Naive-Bayes-Block) and then run the next cell.\n",
    "\n",
    "**Hint:** look at the slides from the lecture on add-1 smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D-evbZy8TgIV",
    "outputId": "0d59b26e-c3c5-4053-c056-5842d63c1da5"
   },
   "outputs": [],
   "source": [
    "print (\"P('stop-sign.'|pos):\",  nb.p_word_given_label_and_alpha(\"stop-sign.\", POS_LABEL, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gp3fSEH1xcW6"
   },
   "source": [
    "### Question 2.6 (5 points)\n",
    "\n",
    "*Prior and Likelihood* \n",
    "\n",
    "As noted before, the Naive Bayes model assumes that all words in a document are independent of one another given the document’s label. Because of this we can write the likelihood of a document as:\n",
    "\n",
    "$P(w_{d1},\\cdots,w_{dn}|y_d) = \\prod_{i=1}^{n}P(w_{di}|y_d)$\n",
    "\n",
    "However, if a document has a lot of words, the likelihood will become extremely small and we’ll encounter numerical underflow. Underflow is a common problem when dealing with probabilistic models; if you are unfamiliar with it, you can get a brief overview on [Wikipedia](https:/en.wikipedia.org/wiki/Arithmetic_underflow). To deal with underflow, a common transformation is to work in log-space.\n",
    "\n",
    "$\\log[P(w_{d1},\\cdots,w_{dn}|y_d)] = \\sum_{i=1}^{n}\\log[P(w_{di}|y_d)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9nPd6o4xdcR"
   },
   "source": [
    "Implement the `log_likelihood` function in the [Naive Bayes Block](#Naive-Bayes-Block). **Hint:** it should make calls to the p word given label and alpha function.\n",
    "\n",
    "Implement the `log_prior` function in the [Naive Bayes Block](#Naive-Bayes-Block). This function takes a class label and returns the log of the fraction of the training documents that are of that label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuul6OY_xqRN"
   },
   "source": [
    "### Question 2.7 (5 points)\n",
    "\n",
    "Naive Bayes is a model that tells us how to compute the posterior\n",
    "probability of a document being of some label (i.e.,\n",
    "$P(y_d|\\mathbf{w_d})$).  Specifically, we do so using bayes rule:\n",
    "\n",
    "  $P(y_d|\\mathbf{w_d}) = \\frac{P(y_d)P(\\mathbf{w_d}|y_d)}{P(\\mathbf{w_d})}$\n",
    "\n",
    "In the previous section you implemented functions to compute both\n",
    "the log prior ($\\log[P(y_d)]$) and the log likelihood\n",
    "($\\log[P( \\mathbf{w_d} |y_d)]$ ). Now, all you're missing is the\n",
    "*normalizer*, $P(\\mathbf{w_d})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAB71vfdxwgi"
   },
   "source": [
    "<font color='red'>Derive the normalizer by expanding $P(\\mathbf{w_d})$.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CrX-imzMx2jV"
   },
   "source": [
    "***Answer in one or two lines here. Provide the formula and define each term in this formula.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7OWn9KEx6Sm"
   },
   "source": [
    "### Question 2.8 (5 points)\n",
    "\n",
    "One way to classify a document is to compute the unnormalized log posterior for both labels and take the argmax (i.e., the label that yields the higher unnormalized log posterior). The unnormalized log posterior is the sum of the log prior and the log likelihood of the document. <font color='red'>Why don’t we need to compute the log normalizer here?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNtHFA3FMy_1"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzD9GRQlyC50"
   },
   "source": [
    "### Question 2.9 (10 points)\n",
    "\n",
    "As we saw earlier, the top 10 words from each class do not give us much to go on when classifying a document. A much more powerful metric is the likelihood ratio, which is defined as\n",
    "\n",
    "$LR(w)=\\frac{P(w|y=\\mathrm{pos})}{P(w|y=\\mathrm{neg})}$\n",
    "\n",
    "A word with LR 3 is 3 times more likely to appear in the positive class than in the negative. A word with LR 0.3 is one-third as likely to appear in the positive class as opposed to the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "30_bgXpvTsGO",
    "outputId": "4e20a9e5-b530-4061-a521-1f3c42a9af33"
   },
   "outputs": [],
   "source": [
    "# Implement the nb.likelihod_ratio function and use it to investigate the likelihood ratio of \"amazing\" and \"dull\"\n",
    "print (\"LIKELIHOOD RATIO OF 'amazing':\", nb.likelihood_ratio('amazing', 0.2))\n",
    "print (\"LIKELIHOOD RATIO OF 'dull':\", nb.likelihood_ratio('dull', 0.2))\n",
    "print (\"LIKELIHOOD RATIO OF 'and':\", nb.likelihood_ratio('and', 0.2))\n",
    "print (\"LIKELIHOOD RATIO OF 'to':\", nb.likelihood_ratio('to', 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1Dlpm1EyJeo"
   },
   "source": [
    "<font color='red'>What is the minimum and maximum possible values the likelihood ratio can take? Does it make sense that $LR('amazing') > LR('to')$?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8UAo19cM1ld"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zg7q0UjLyKbc"
   },
   "source": [
    "Find the word in the vocabulary with the highest liklihood ratio below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bI9MObvQTvHQ",
    "outputId": "e1e0ed10-9d9b-4492-e0cd-d45d10dc207f"
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6Q1OSnPygCO"
   },
   "source": [
    "### Question 2.10 (5 points)\n",
    "\n",
    "The unnormalized log posterior is the sum of the log prior and the log likelihood of the document. Implement the `unnormalized_log_posterior` function and the `classify` function in the [Naive Bayes Block](#Naive-Bayes-Block). The `classify` function should use the unnormalized log posteriors but should not compute the normalizer. Once you implement the `classify` function, we'd like to evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TZUJcivdTxXu",
    "outputId": "b759f3a9-be1e-48e0-d573-632ccea19203"
   },
   "outputs": [],
   "source": [
    "print (nb.evaluate_classifier_accuracy(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oC0zcmV-ymJX"
   },
   "source": [
    "### Question 2.11 (5 points)\n",
    "\n",
    "Try evaluating your model again with a smoothing parameter of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xPCsmV0vT9tL",
    "outputId": "11310bfd-9e59-47f3-8cbe-0b2b6f743c36"
   },
   "outputs": [],
   "source": [
    "print (nb.evaluate_classifier_accuracy(1000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_sU8Iudyo0U"
   },
   "source": [
    "<font color='red'>Does the accuracy go up or down when alpha is raised to 1000? Why do you think this is?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSNHP6JzM7YQ"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6WdGIx8Oyta9"
   },
   "source": [
    "### Question 2.12 (5 points)\n",
    "\n",
    "Find a review that your classifier got wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "S9CaUcj6ywUv",
    "outputId": "b9b02332-05d9-47f1-eb2c-9c5b908c042d"
   },
   "outputs": [],
   "source": [
    "# In this cell, print out a review your classifier got wrong, along with its label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUro9Tlzy0N3"
   },
   "source": [
    "<font color='red'>What are two reasons your system might have misclassified this example? What improvements could you make that may help your system classify this example correctly?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQRznrQCM9TR"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzEmIcT1y205"
   },
   "source": [
    "### Question 2.13 (5 points)\n",
    "\n",
    "Often times we care about multi-class classification rather than binary classification.\n",
    "\n",
    "<font color='red'>How many counts would we need to keep track of if the model were modified to support 5-class classification?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "743UlUGOM_hv"
   },
   "source": [
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTxHxdG5BpQU"
   },
   "source": [
    "## Extra Credit (Up to 10 points)\n",
    "\n",
    "If you don't want to do the extra credit, you can stop here! Otherwise... keep reading...\n",
    "In this assignment, we use whitespace tokenization to create a bag-of-unigrams representation for the movie reviews. It is possible to improve this represetation to improve your classifier's performance. Use your own code or an external library such as nltk to perform tokenization, text normalization, word filtering, etc. Fill out your work in `def tokenize_doc_and_more` (below) and then show improvement by running the cells below.\n",
    "\n",
    "Roughly speaking, the larger performance improvement, the more extra credit. We will also give points for the effort in the evaluation and analysis process. For example, you can split the training data into training and validation set to prevent overfitting, and report results from trying different versions of features. You can also provide some qualitative examples you found in the dataset to support your choices on preprocessing steps. Whatever you choose to try, make sure to describe your method and the reasons that you hypothesize for why the method works. Be sure to explain what your code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9MsACwTcEMZx",
    "outputId": "2e853082-4ae5-4821-a256-bd356d2f75df"
   },
   "outputs": [],
   "source": [
    "def tokenize_doc_and_more(doc): \n",
    "    \"\"\"\n",
    "    Return some representation of a document.\n",
    "    At a minimum, you need to perform tokenization, the rest is up to you. \n",
    "    \"\"\"\n",
    "    # Implement me!\n",
    "    bow = defaultdict(float)\n",
    "    # your code goes here\n",
    "\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "pORAesdtFK65",
    "outputId": "d76e8f4f-c073-4d2b-ac45-653aca2e8a88"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc_and_more)\n",
    "nb.train_model()\n",
    "nb.evaluate_classifier_accuracy(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "440ZSusiFPoN"
   },
   "source": [
    "Use cells at the bottom of this notebook to explain what you did in `tokenize_doc_and_more`. Include any experiments or explanations that you used to decide what goes in your function. Doing a good job examining, explaining and justifying your work with small experiments and comments is as important as making the accuracy number go up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpg8eU9wNBci"
   },
   "source": [
    "***Explain what you did here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to submit this problem set:\n",
    "- Write all the answers in this iPython notebook. Once you are finished (1) generate the PDF file (`File -> Print Preview`, and print to PDF), 2) ZIP the PDF and this Jupyter Notebook (.ipynb), and 3) upload the ZIP file to Canvas.\n",
    "  \n",
    "- **Important:** check your PDF before you turn it in to Canvas to make sure it exported correctly.\n",
    "\n",
    "- When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. Then you'll be sure it's actually right. One handy way to do this is by clicking `Runtime -> Run All` in the notebook menu."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HWK2_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
